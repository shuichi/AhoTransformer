# Default configuration for AhoTransformer experiments

# Model configuration
model:
  vocab_size: 100
  d_model: 256
  nhead: 4
  num_encoder_layers: 3
  num_decoder_layers: 3
  dim_feedforward: 512
  dropout: 0.1
  max_seq_length: 512

# Training configuration
training:
  output_dir: outputs
  epochs: 10
  batch_size: 32
  learning_rate: 0.0001
  weight_decay: 0.0
  device: auto
  seed: 42
  log_level: INFO

  # Data splits
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1

  # Learning rate scheduler
  use_scheduler: true
  scheduler_step_size: 10
  scheduler_gamma: 0.1

  # Early stopping
  early_stopping_patience: 5

  # Dummy data settings (for testing)
  num_samples: 1000

# Data configuration
data:
  # Add your data paths and settings here
  # train_path: data/train.txt
  # val_path: data/val.txt
  # test_path: data/test.txt
  pad_idx: 0
  bos_idx: 1
  eos_idx: 2
